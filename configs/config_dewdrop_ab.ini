[preprocessing]
pdb_path = data/pdb_1700/
sequence_path = data/nanobody_1700_unique_seq.csv
pickle_path = data/nanofold_input_ext_sabdab_curated_1700.pickle
template_coords = ./cg_X0.npz
model_type = nb
compute_torsion_angles = false
differential_weight_fwr_cdr_fape = 3
weight_cdr_cdr_pairs_fape = 
train_val_test_split_ratio = [0.82, 0.08, 0.1] # better train split for dewdrop with batchsize=200

[dewdrop]
; List of experiments to run
experiments = ["bs=100", "bs=200", "bs=350"]
; List of tuples, must have the same number of entries as the number of experiments
devices_list = [(1), (1), (1)]
; Batch size for each experiment 
batchsize_list = [100, 200, 350]
; ensemble size for each experiment
ensemblesize_list = [128, 128, 128]
; label pool max size 
final_labelpool_size = 800

[training]
training_config_path = models/dewdrop/training.json
model_config_path = models/dewdrop/config.json
; Initial weights to use (can be left empty)
initial_weights = models/dewdrop/ab_weights_v4.pt 
; Output directory for checkpoints and logging
output_dir = model_logs/dewdrop
run_name = dewdrop_bs=100
version_id = v2
train_data_path = data/nanofold_input_ext_sabdab_curated_1700_train.pickle
validation_data_path = data/nanofold_input_ext_sabdab_curated_1700_validation.pickle
test_data_path = data/nanofold_input_ext_sabdab_curated_1700_test.pickle
devices = 1
use_ensemble_cache = True


[inference]
config_path = models/models_with_recycling/config.json
model_ckpt = models/models_with_recycling/7_11_run_3_last.ckpt
model_type = nb
sequence_path = benchmarking/nanobody_1700_unique_seq.csv
ncpu = 
output_dir = benchmarking/predicted
refine = true
n_seeds = 5

[benchmarking]
sequence_path = benchmarking/nanofold_int_nb_test_input_56.csv
ground_truth_pdb_path = benchmarking/int_nb_56
predicted_pdb_path = benchmarking/predicted
prefix = run_test-v1

