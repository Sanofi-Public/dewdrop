{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cloud-home/U1034010/.magellan/conda/envs/nanofold/lib/python3.9/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "from Bio import PDB, Seq, pairwise2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import sys\n",
    "import shutil\n",
    "import os\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from openfold_light.residue_constants import restype_3to1, restype_1to3 # map 3 letters amino acid code to 1 letter code\n",
    "from cg import cg_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from parsed VH sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfp=\"./master_pdb_parsed_v2_curated_v4_multichain_Ag_filtered_v2_separated_all_VH_complexes_unique_seq_level_with_seq.csv\"\n",
    "df = pd.read_csv(csvfp)\n",
    "\n",
    "# get all the files names from \"Name\"\n",
    "names = df[\"Name\"].str.split('>').str[0].to_list() # e.g. \"7lx5-assembly1\" or \"5ku2\" \n",
    "# df[\"Name\"] = df[\"Name\"].str.split('>').str[0]\n",
    "subchain_id = df[\"Chain_VH\"].to_list() # e.g. \"B_0\" or \"B-2_0\"\n",
    "sequence_vh = df[\"Sequence_VH\"].to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download all raw the files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decompress .gz files...: 100%|██████████| 1412/1412 [00:06<00:00, 216.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# save target filenames\n",
    "outfp = \"./pdb_1700_raw\"\n",
    "with open(\"./cache_filenames.txt\", \"w\") as file: \n",
    "    file.write(\", \".join(names))\n",
    "os.makedirs(outfp, exist_ok=True)\n",
    "\n",
    "# change permission \n",
    "subprocess.run([\"chmod\", \"+x\", \"./batch_download.sh\"], check=True)\n",
    "\n",
    "# run the shell script \n",
    "subprocess.run([\"bash\", \"./batch_download.sh\", \"-f\", \"./cache_filenames.txt\", \"-o\", outfp, \"-c\"], stdout=subprocess.DEVNULL)\n",
    "\n",
    "# delete cached files names \n",
    "os.remove(\"./cache_filenames.txt\")\n",
    "\n",
    "# gzip decompress all files \n",
    "for fp in tqdm(os.listdir(outfp), desc=\"Decompress .gz files...\"):\n",
    "    with gzip.open(os.path.join(outfp, fp), \"rb\") as f_in, \\\n",
    "        open(os.path.join(outfp, fp.strip(\".gz\")), \"wb\") as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "    # delete gzip files \n",
    "    os.remove(os.path.join(outfp, fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract entire target VH chain from raw files\n",
    "- then record all the coordinates of the corresponding amino acid in given sequence \n",
    "- non-existing coordinates are set as nan \n",
    "- amino acid that doesn't exist in the curated sequence, but appear to be unknown in the .cif record, should be X\n",
    "- save the result .cif files in `pdb_1700`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1709 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 114/1709 [00:45<10:16,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FileNotFound: 7evw-assembly1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1709/1709 [13:24<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "def parse_structure(subcid, curated_seq, cid, aligned_sequences):\n",
    "    # parse the target file \n",
    "    parser = PDB.MMCIFParser(QUIET=True)\n",
    "    try: # 7evw-assembly1 isn't downloaded so skip with try-except\n",
    "        structure = parser.get_structure(name, os.path.join(outfp, name+\".cif\"))\n",
    "        model = structure[0]\n",
    "\n",
    "        # extract chain \n",
    "        chain = model[cid]    \n",
    "\n",
    "        # extract both residue objects and their string sequences\n",
    "        chain_residues = [(restype_3to1[residue.get_resname()], residue) for residue in chain if residue.get_resname() in restype_3to1]\n",
    "        chain_seq = ''.join([restype_3to1[residue.get_resname()] for residue in chain if residue.get_resname() in restype_3to1])\n",
    "\n",
    "\n",
    "        # align curacted seq with chain seq\n",
    "        if chain_seq != curated_seq: \n",
    "\n",
    "            # note on parameters: \n",
    "            # [seq1, seq2, \n",
    "            #  reward given to identical character,\n",
    "            #  deduction for non-identical character, \n",
    "            #  deduction for open gap,\n",
    "            #  deduction for extending sequence]\n",
    "            alignment = pairwise2.align.globalms(chain_seq, curated_seq, 5, -3, -1., -.5, gap_char='X')[0]\n",
    "\n",
    "            # EX: \n",
    "            # len(seqA) == len(seqB)\n",
    "            # chain_seq   = EVQLQESGGGLVYDSLRLSCASSRSIDGINIMRWYRQAPGKQRGMVAVVTGWGSTNYVDSVKGRFIISRDSAKDTVYLQMNNLKPEDTAVYSCNAIYRGSEYWGQGTQVTVS \n",
    "            # curated_seq = ESGEMLFTVKKDSLRLSCASSRSIDGINIMRWYRQAPGKQRGMVAVVTGWGSTNYVDSVKGRFIISRDSAKDTVYLQMNNLKPEDTAVYSCNAIYRGSEYWGQGTQVTVS \n",
    "            # seqA = EVQLQESGGGXXLXXVYXXDSLRLSCASSRSIDGINIMRWYRQAPGKQRGMVAVVTGWGSTNYVDSVKGRFIISRDSAKDTVYLQMNNLKPEDTAVYSCNAIYRGSEYWGQGTQVTVS\n",
    "            # seqB = XXXXXESXXGEMLFTVXKKDSLRLSCASSRSIDGINIMRWYRQAPGKQRGMVAVVTGWGSTNYVDSVKGRFIISRDSAKDTVYLQMNNLKPEDTAVYSCNAIYRGSEYWGQGTQVTVS\n",
    "            aligned_chain_seq = alignment.seqA\n",
    "            aligned_curated_seq = alignment.seqB\n",
    "\n",
    "            # Need to re-index the chain_residues according to the aligned chain sequence\n",
    "            aligned_chain_residues = []\n",
    "            chain_indx = 0\n",
    "            for aligned_indx, aligned_restype in enumerate(aligned_chain_seq):\n",
    "                # (1) inserted unknown residue\n",
    "                if aligned_restype == 'X':\n",
    "                    aligned_chain_residues.append((aligned_restype, None)) # No residue assigned to X, will create a new one later \n",
    "                # (2) keep original chain residue \n",
    "                else: \n",
    "                    chain_restype, chain_residue = chain_residues[chain_indx]\n",
    "                    aligned_chain_residues.append((aligned_restype, chain_residue))\n",
    "                    chain_indx += 1    \n",
    "\n",
    "        else: \n",
    "            aligned_chain_seq = chain_seq \n",
    "            aligned_chain_residues = chain_residues\n",
    "            aligned_curated_seq = curated_seq\n",
    "\n",
    "\n",
    "        # construct new structure\n",
    "        new_structure = PDB.Structure.Structure(id=name[:4])\n",
    "        new_model = PDB.Model.Model(id=model.id)\n",
    "        new_chain = PDB.Chain.Chain(id=cid)\n",
    "\n",
    "        # insert aligned residue according to aligned curated sequence  \n",
    "        rid = 1 # new residue id \n",
    "        for ri, curated_restype in enumerate(aligned_curated_seq): \n",
    "            chain_residue = aligned_chain_residues[ri][1]\n",
    "            chain_restype = aligned_chain_seq[ri]\n",
    "\n",
    "            # if residue is X or unknown, ignore the residue in the original protein\n",
    "            if curated_restype == 'X' or curated_restype not in restype_1to3: \n",
    "                continue\n",
    "            # if residue is the same as the original protein, copy the residue\n",
    "            elif curated_restype == chain_restype:\n",
    "                new_residue = PDB.Residue.Residue((' ', rid, ' '), restype_1to3[curated_restype], chain_residue.segid)\n",
    "\n",
    "                # copy the atoms\n",
    "                for atom in chain_residue:\n",
    "                    new_residue.add(atom.copy()) \n",
    "\n",
    "                # add residue to the chain \n",
    "                new_chain.add(new_residue)\n",
    "                rid += 1\n",
    "            # if residue is different from the original protein, create a new residue with the curated residue type\n",
    "            else:\n",
    "                assert chain_restype == 'X', \"Chain residue is not X when curated residue is different but not X.\"\n",
    "                new_residue = PDB.Residue.Residue((' ', rid, ' '), restype_1to3[curated_restype], \"\")\n",
    "\n",
    "                # choose the first atoms assignment from CG group as placeholder\n",
    "                # TODO: change this to the average of the neighboring atoms\n",
    "                coord = np.array([np.nan, np.nan, np.nan]) \n",
    "                for serial_num, atom_name in enumerate(cg_dict[restype_1to3[curated_restype]][0]):\n",
    "                    new_atom = PDB.Atom.Atom(name=atom_name, \n",
    "                                            coord=coord, \n",
    "                                            bfactor=0.0, \n",
    "                                            occupancy=1.0, \n",
    "                                            altloc=\" \",\n",
    "                                            fullname=f\" {atom_name} \", \n",
    "                                            serial_number=serial_num,\n",
    "                                            element=atom_name[0])\n",
    "                    new_residue.add(new_atom)\n",
    "\n",
    "                new_chain.add(new_residue)\n",
    "                rid += 1\n",
    "\n",
    "        # add new chain to model and model to structure \n",
    "        new_model.add(new_chain)\n",
    "        new_structure.add(new_model)\n",
    "        \n",
    "        # save aligned seq to a list \n",
    "        aligned_sequences.append(aligned_curated_seq)\n",
    "        \n",
    "        # write the curated structure to file \n",
    "        cifio = PDB.mmcifio.MMCIFIO()\n",
    "        cifio.set_structure(new_structure)\n",
    "        cifio.save(destfp+f'/{name}_{subcid}.cif')\n",
    "\n",
    "    except FileNotFoundError as e: \n",
    "        tqdm.write(f\"\\nFileNotFound: {name}\")\n",
    "\n",
    "    \n",
    "\n",
    "outfp = \"./pdb_1700_raw\"\n",
    "destfp = \"./pdb_1700\"\n",
    "os.makedirs(destfp, exist_ok=True)\n",
    "count_diff = 0 # 1252 (729 without X) chain sequence is different from the subchains\n",
    "aligned_sequences = []\n",
    "\n",
    "\n",
    "# TODO: Improve runtime to use multiprocessing\n",
    "pbar = tqdm(names)\n",
    "for indx, name in enumerate(pbar): \n",
    "    # get the corresponding chain and sequence\n",
    "    subcid = subchain_id[indx] # e.g. K_0\n",
    "    curated_seq = sequence_vh[indx] # e.g. QVQLQESGGGLV...\n",
    "    cid, subid = subcid.split('_')\n",
    "    parse_structure(subcid, curated_seq, cid, aligned_sequences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename the csv columns \n",
    "* From Chain_VH,Name,Sequence_VH\n",
    "* To uid,seq,chain_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain_id</th>\n",
       "      <th>uid</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_0</td>\n",
       "      <td>7lx5-assembly1</td>\n",
       "      <td>QVQLQESGGGLVQPGGSLRLSCAASGFTFRRYLMGWARQVPGKGLE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N_0</td>\n",
       "      <td>6p9y-assembly1</td>\n",
       "      <td>QVQLQESGGGLVQPGGSLRLSCAASGFTFSNYKMNWVRQAPGKGLE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E_0</td>\n",
       "      <td>4w2q-assembly3</td>\n",
       "      <td>KVQLQESGGGLVQVGGSLRLSCKASGFTFRSSAMGWYRRAPGKQRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_0</td>\n",
       "      <td>4x7e-assembly1</td>\n",
       "      <td>DVQLVESGGGLVQPGGSLRLSCAASGSIFSIYAMGWYRQAPGKQRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B_0</td>\n",
       "      <td>7x2m-assembly1</td>\n",
       "      <td>QVQLQESGGGLVQPGGSLRLSCAASGDTLDLYAIGWFRQTPGEERE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chain_id             uid                                                seq\n",
       "0      A_0  7lx5-assembly1  QVQLQESGGGLVQPGGSLRLSCAASGFTFRRYLMGWARQVPGKGLE...\n",
       "1      N_0  6p9y-assembly1  QVQLQESGGGLVQPGGSLRLSCAASGFTFSNYKMNWVRQAPGKGLE...\n",
       "2      E_0  4w2q-assembly3  KVQLQESGGGLVQVGGSLRLSCKASGFTFRSSAMGWYRRAPGKQRE...\n",
       "3      C_0  4x7e-assembly1  DVQLVESGGGLVQPGGSLRLSCAASGSIFSIYAMGWYRQAPGKQRE...\n",
       "4      B_0  7x2m-assembly1  QVQLQESGGGLVQPGGSLRLSCAASGDTLDLYAIGWFRQTPGEERE..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./master_pdb_parsed_v2_curated_v4_multichain_Ag_filtered_v2_separated_all_VH_complexes_unique_seq_level_with_seq.csv\")\n",
    "df = df.drop(df.loc[df[\"Name\"].str.contains(\"7evw-assembly1\")].index).reset_index(drop=True) # this one is not working \n",
    "\n",
    "df = df.rename(columns={\n",
    "                    \"Chain_VH\": \"chain_id\",\n",
    "                    \"Name\": \"uid\",\n",
    "                    \"Sequence_VH\": \"seq\",\n",
    "                })\n",
    "df[\"uid\"] = df[\"uid\"].str.split(\">\").str[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check: shouldn't be any X in the seq \n",
    "# df['seq'].str.contains('X').sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./nanobody_1700_unique_seq.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1708, 4)\n",
      "1708\n",
      "|----->  (1708, 4)\n"
     ]
    }
   ],
   "source": [
    "# # remove nanobody entries that don't exist\n",
    "# print(df.shape)\n",
    "# targets = set(os.listdir(\"./pdb_1700\"))\n",
    "# keeprows = df.apply(lambda r: str(r[\"uid\"] + '_' + r['chain_id'] + \".cif\") in targets, axis=1)\n",
    "# print(keeprows.sum())\n",
    "# df = df.loc[keeprows]\n",
    "# print(\"|-----> \", df.shape) # Weird that the numbers doesn't change here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"./nanobody_1700_unique_seq.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove trailing integer on chain_id (A_0 --> A)\n",
    "# df1 = pd.read_csv(\"./master_pdb_parsed_v2_curated_v4_multichain_Ag_filtered_v2_separated_all_VH_complexes_unique_seq_level_with_seq.csv\")\n",
    "# df1 = df1.drop(df1.loc[df1[\"Name\"].str.contains(\"7evw-assembly1\")].index).reset_index(drop=True)\n",
    "# df1 = df1.rename(columns={\n",
    "#                     \"Chain_VH\": \"chain_id\",\n",
    "#                     \"Name\": \"uid\",\n",
    "#                     \"Sequence_VH\": \"original_seq\",\n",
    "#                 })\n",
    "\n",
    "\n",
    "# df2 = pd.read_csv(\"./nanobody_1700_unique_seq.csv\")\n",
    "# df2[\"chain_id\"] = df1[\"chain_id\"]\n",
    "# df2[\"seq\"] = df1[\"original_seq\"]\n",
    "# df2.to_csv(\"./nanobody_1700_unique_seq.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up raw file to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up all downloaded raw files \n",
    "# outfp = \"./pdb_1700_raw\"\n",
    "# shutil.rmtree(outfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanofold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "metadata": {
   "interpreter": {
    "hash": "756a062aef48f88bb6c204c2fb789c036f4c69b68ba1fd774807f83e5ac7f83f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
