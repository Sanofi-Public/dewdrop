{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1672b974-0061-4984-8f61-8842fdc22d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/NanoFold/lib/python3.10/site-packages/_distutils_hack/__init__.py:54: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import GPT2Model, GPT2LMHeadModel, GPT2Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e344d53d",
   "metadata": {},
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e407db-b33c-4960-ae29-60749bea36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_config = GPT2Config(\n",
    "    vocab_size=32,\n",
    "    n_positions=1024,\n",
    "    n_embd=16,\n",
    "    n_layer=2,\n",
    "    n_head=4,\n",
    "    n_inner=None,\n",
    "    activation_function=\"gelu_new\",\n",
    "    resid_pdrop=0.1,\n",
    "    embd_pdrop=0.1,\n",
    "    attn_pdrop=0.1,\n",
    ")\n",
    "\n",
    "gen_model = GPT2LMHeadModel(gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d5013c-8400-49c0-a2e8-c236d1cbe3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1100, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seqs = 1100\n",
    "seq_length = 100\n",
    "test_size = 100\n",
    "\n",
    "prompts = torch.randint(16, (n_seqs, 32))\n",
    "\n",
    "in_seqs = gen_model.generate(\n",
    "    inputs = prompts,\n",
    "    max_new_tokens=seq_length,\n",
    "    do_sample=True,\n",
    "    top_k=0,\n",
    ")[:,32:].detach()\n",
    "in_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d56c10de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1100, 164])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.generate(\n",
    "    inputs = prompts,\n",
    "    max_new_tokens=132,\n",
    "    do_sample=True,\n",
    "    top_k=0,\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8792403f-813b-4be9-85aa-cf86d7836b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "import torch\n",
    "\n",
    "def backward(self, *args, **kwargs):\n",
    "    print(n_passes)\n",
    "    n_passes += 1\n",
    "    return self._old_backward(*args, **kwargs)\n",
    "    \n",
    "\n",
    "class BertEmbeddor(BertModel):\n",
    "    def __init__(self, config=None, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.out_size = getattr(config, 'out_size', 0) or config.hidden_size\n",
    "        assert self.out_size <= config.hidden_size\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "        \n",
    "    def forward(self, input_ids, labels=None, **kwargs):\n",
    "        #global n_passes\n",
    "        #n_passes = 0\n",
    "        with torch.autograd.detect_anomaly():\n",
    "            output = super().forward(input_ids=input_ids, **kwargs).last_hidden_state[...,:self.out_size]\n",
    "            if labels is not None:\n",
    "                loss = self.loss(output, labels)\n",
    "                #loss._old_backward = loss.backward\n",
    "                #loss.backward = backward.__get__(loss)\n",
    "                return loss, output.detach()\n",
    "        return output        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c55a90d8-8798-4ca8-9c7d-dce4d867e59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "<__main__.Fun object at 0x7f0371d840d0> 2\n"
     ]
    }
   ],
   "source": [
    "def method(self, arg):\n",
    "    print(self, arg)\n",
    "    \n",
    "class Fun:\n",
    "    pass\n",
    "f = Fun()\n",
    "print(vars(f))\n",
    "\n",
    "f = Fun()\n",
    "f.run = method.__get__(f)\n",
    "f.run(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f38e42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run': <bound method method of <__main__.Fun object at 0x7f014dbe9030>>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22325cc6-8447-43b5-ac27-f63e3f58ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_config = BertConfig(\n",
    "    vocab_size=32,\n",
    "    hidden_size=16,\n",
    "    num_hidden_layers=2,\n",
    "    num_attention_heads=4,\n",
    "    intermediate_size=32,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=1024,\n",
    ")\n",
    "\n",
    "true_process = BertEmbeddor(true_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c10ce5-ced0-43d7-9517-8b6b978d0f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1100, 100, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_seq = true_process(in_seqs).detach()\n",
    "out_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8157fd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_seqs.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88467ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.32138336e-01,  4.04119998e-01,  4.49637115e-01, ...,\n",
       "          1.12798786e+00,  9.37545538e-01, -1.25721264e+00],\n",
       "        [-1.09192860e+00,  2.27750745e-02,  1.65723300e+00, ...,\n",
       "         -1.72552323e+00,  5.52578509e-01,  1.43263984e+00],\n",
       "        [ 1.96849740e+00, -1.89418435e-01, -5.67110538e-01, ...,\n",
       "          7.32037649e-02,  1.34004724e+00, -2.08085492e-01],\n",
       "        ...,\n",
       "        [ 7.38770962e-01,  7.88826168e-01, -7.56235957e-01, ...,\n",
       "          5.25630005e-02,  2.06012702e+00, -1.36556506e+00],\n",
       "        [ 2.48281121e-01,  1.48547143e-01,  3.16754691e-02, ...,\n",
       "          1.30367851e+00,  1.03389490e+00, -3.73424813e-02],\n",
       "        [-7.96971619e-01, -1.79041788e-01, -8.16561997e-01, ...,\n",
       "          1.45417917e+00,  1.06448293e+00,  1.95972309e-01]],\n",
       "\n",
       "       [[ 6.25927508e-01,  5.30399442e-01,  9.77656305e-01, ...,\n",
       "          1.01721370e+00,  6.38967812e-01, -7.20833302e-01],\n",
       "        [ 6.34040087e-02, -1.71405911e+00,  3.50597128e-02, ...,\n",
       "         -7.55399346e-01,  6.27350748e-01,  4.49921817e-01],\n",
       "        [ 1.44918990e+00, -1.55844957e-01, -2.36765966e-01, ...,\n",
       "          3.84053022e-01,  5.86579144e-01, -1.51270187e+00],\n",
       "        ...,\n",
       "        [ 1.42841086e-01,  1.16329096e-01, -3.01431477e-01, ...,\n",
       "          4.41791296e-01,  1.23671234e+00, -2.26874098e-01],\n",
       "        [ 1.09165001e+00, -3.82110506e-01,  1.69496238e-02, ...,\n",
       "          3.71210814e-01,  3.29989314e-01, -1.06373996e-01],\n",
       "        [ 2.88781196e-01,  5.96393406e-01, -1.21151960e+00, ...,\n",
       "          1.04630935e+00,  5.15890837e-01, -1.49753320e+00]],\n",
       "\n",
       "       [[-4.51688170e-02,  4.18133676e-01,  3.24787706e-01, ...,\n",
       "          2.26175219e-01,  1.02643216e+00, -1.08956051e+00],\n",
       "        [-2.13491365e-01, -5.88747144e-01,  5.89768648e-01, ...,\n",
       "         -6.85225546e-01,  2.29804605e-01, -4.99105543e-01],\n",
       "        [ 1.05593514e+00, -2.22259194e-01, -1.09942779e-01, ...,\n",
       "          7.42513835e-01, -1.47757649e-01, -1.32893598e+00],\n",
       "        ...,\n",
       "        [ 2.28085771e-01,  1.90638888e+00,  1.34432659e-01, ...,\n",
       "          2.01065794e-01,  1.64068818e+00, -7.86057591e-01],\n",
       "        [ 1.14084296e-01, -1.97670090e+00,  2.88179666e-01, ...,\n",
       "          6.47447586e-01,  3.04254085e-01,  2.88706839e-01],\n",
       "        [ 8.05298567e-01, -6.21200465e-02, -1.27055705e+00, ...,\n",
       "          1.64103103e+00,  8.99838507e-01,  2.79183000e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.79399592e-01,  5.34235299e-01,  3.91168296e-02, ...,\n",
       "          3.82132441e-01,  1.71411049e+00, -1.30028319e+00],\n",
       "        [ 6.48408802e-03,  3.37263465e-01, -2.68766165e-01, ...,\n",
       "         -4.76994127e-01,  9.81401920e-01, -3.99575889e-01],\n",
       "        [ 2.82369971e-01, -2.57514775e-01,  2.64350832e-01, ...,\n",
       "          3.56875479e-01, -3.19597602e-01, -1.55994594e+00],\n",
       "        ...,\n",
       "        [-3.59438300e-01,  5.51026702e-01, -8.36400807e-01, ...,\n",
       "         -1.92859173e-02,  1.15358126e+00, -1.92168221e-01],\n",
       "        [-1.14005935e+00, -2.75231391e-01,  2.31753886e-01, ...,\n",
       "          1.01879990e+00,  1.16327536e+00,  8.22250664e-01],\n",
       "        [ 9.13444459e-02,  1.36778384e-01,  1.46944299e-02, ...,\n",
       "          1.67718005e+00,  5.29933393e-01, -1.91156745e-01]],\n",
       "\n",
       "       [[ 5.09975851e-01,  5.43087363e-01,  7.36541972e-02, ...,\n",
       "          4.12147194e-01,  1.74439085e+00, -1.28664267e+00],\n",
       "        [ 2.58965760e-01,  4.02810395e-01, -2.21355841e-01, ...,\n",
       "         -4.36960936e-01,  5.73975220e-02, -3.54696989e-01],\n",
       "        [-6.67850733e-01,  2.23807944e-03,  1.28351021e+00, ...,\n",
       "         -7.71239340e-01, -7.55758211e-02,  1.28103733e-01],\n",
       "        ...,\n",
       "        [ 1.56196129e+00,  6.53706014e-01, -1.73314703e+00, ...,\n",
       "         -5.37166834e-01,  3.64518426e-02, -2.38920188e+00],\n",
       "        [ 3.16385657e-01,  5.22013664e-01,  2.55598009e-01, ...,\n",
       "          4.41070020e-01,  2.18491361e-01,  5.45438468e-01],\n",
       "        [ 6.25552714e-01, -1.94509998e-01, -1.28938270e+00, ...,\n",
       "          1.38303757e+00,  7.06734776e-01,  1.34836331e-01]],\n",
       "\n",
       "       [[ 2.45831117e-01, -1.20999944e+00,  1.03675210e+00, ...,\n",
       "          2.84918904e-01,  9.45694029e-01, -1.34864795e+00],\n",
       "        [-7.44245723e-02, -8.60630751e-01,  2.51176685e-01, ...,\n",
       "         -1.17989337e+00, -8.60437751e-02,  8.69243920e-01],\n",
       "        [ 1.48200309e+00,  3.07062030e-01, -1.65505677e-01, ...,\n",
       "          1.15757596e+00,  3.18370014e-01, -1.56095910e+00],\n",
       "        ...,\n",
       "        [ 5.60347103e-02,  7.57097781e-01, -7.75815904e-01, ...,\n",
       "          2.84626007e-01,  2.03407526e+00, -1.37826407e+00],\n",
       "        [ 3.25205266e-01,  5.23336709e-01,  2.49441355e-01, ...,\n",
       "          4.35992569e-01,  2.22628340e-01,  5.48179507e-01],\n",
       "        [ 7.11206377e-01,  2.69186795e-01, -3.87404352e-01, ...,\n",
       "          1.83617806e+00,  1.32987189e+00, -1.08928752e+00]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_seq.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1165dd71-5fbc-4fcd-9743-5205f6893763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21680"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in true_process.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0273a8",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7fc8010-c0ee-4847-9d30-acabc0eb8671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids, labels, attention_mask=None):\n",
    "        self.input_ids = torch.as_tensor(input_ids, dtype=torch.long)\n",
    "        self.labels = torch.as_tensor(labels, dtype=torch.float)\n",
    "        self.attention_mask = torch.as_tensor(attention_mask) if attention_mask is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.attention_mask is not None:\n",
    "            return {\n",
    "                'input_ids': self.input_ids[idx],\n",
    "                'attention_mask': self.attention_mask[idx],\n",
    "                'labels': self.labels[idx],   # embeddings as labels\n",
    "            }\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'labels': self.labels[idx],  # embeddings as labels\n",
    "        }\n",
    "\n",
    "test_data = EmbeddingDataset(in_seqs[:test_size], labels=out_seq[:test_size])\n",
    "train_data = EmbeddingDataset(in_seqs[test_size:], labels=out_seq[test_size:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c067f227-bd15-4e56-b976-d5ae4916904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = BertConfig(\n",
    "    out_size=16,\n",
    "    vocab_size=32,\n",
    "    hidden_size=32,\n",
    "    num_hidden_layers=4,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=64,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=1024,\n",
    ")\n",
    "\n",
    "model = BertEmbeddor(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de1eb955-1d2f-4355-b4af-1c01b06a8496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/NanoFold/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainerCallback, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "import csv\n",
    "import os\n",
    "\n",
    "class TestLossCallback(TrainerCallback):\n",
    "\n",
    "    def __init__(self, logging_dir, file_name=\"test_loss.csv\"):\n",
    "        # Set the output file path to the specified logging directory and file name\n",
    "        self.output_file = os.path.join(logging_dir, file_name)\n",
    "        \n",
    "        # Write header to the CSV file\n",
    "        with open(self.output_file, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"epoch\", \"test_loss\"])\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        # Get validation loss from the logs\n",
    "        test_loss = state.log_history[-1][\"eval_loss\"]\n",
    "        epoch = state.epoch\n",
    "\n",
    "        # Append validation loss to the file\n",
    "        with open(self.output_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch, test_loss])\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=100,\n",
    "    per_device_train_batch_size=8,\n",
    "    no_cuda=False,\n",
    "    warmup_steps=10,\n",
    "    weight_decay=0.01,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    save_total_limit=2,\n",
    "    save_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    load_best_model_at_end = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=10, early_stopping_threshold=1e-5),\n",
    "        TestLossCallback(logging_dir=training_args.logging_dir, file_name=\"test_loss.csv\")\n",
    "    ], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b3beeb8-8914-40f5-b20b-8233e084b825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_anomaly_enabled(True, True)\n",
    "torch.is_anomaly_enabled()\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e58af97-b7ac-4a9d-a660-2d2ed413d333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9875' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9875/12500 19:21 < 05:08, 8.50 it/s, Epoch 79/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.110869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.105959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.103810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.102910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.102388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.101862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.101634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.141900</td>\n",
       "      <td>0.101308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.141900</td>\n",
       "      <td>0.101115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.141900</td>\n",
       "      <td>0.100903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.141900</td>\n",
       "      <td>0.100786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.100656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.100599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.100481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.100362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.100277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.100309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.100132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.100137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.100029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.100082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.100017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.099957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.099994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.099947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.099951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.099892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.099877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.099861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.099859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.099849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.099794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.099786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.099812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.099771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.099794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.099771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.099787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.099770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.099765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.099740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.099751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.099740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.099723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.099742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.099675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.099712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.099716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.099682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.099654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.099697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.099658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.099657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.099657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.099650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.099646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.099638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.099647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.127400</td>\n",
       "      <td>0.099655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.127400</td>\n",
       "      <td>0.099626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.127400</td>\n",
       "      <td>0.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.127400</td>\n",
       "      <td>0.099628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.099625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.099602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.099604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.099607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.127100</td>\n",
       "      <td>0.099599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.127100</td>\n",
       "      <td>0.099586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.127100</td>\n",
       "      <td>0.099580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.127100</td>\n",
       "      <td>0.099602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.099608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.099597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.099615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.099588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.099573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.099578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.099584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_129363/3020326408.py:20: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9875, training_loss=0.13115360385556765, metrics={'train_runtime': 1161.4403, 'train_samples_per_second': 86.1, 'train_steps_per_second': 10.762, 'total_flos': 1673030400000.0, 'train_loss': 0.13115360385556765, 'epoch': 79.0})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1f53eb2-f1cb-403b-b901-de60ea06a0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.46.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
